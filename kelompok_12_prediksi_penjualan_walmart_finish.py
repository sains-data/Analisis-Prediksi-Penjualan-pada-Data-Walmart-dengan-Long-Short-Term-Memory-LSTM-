# -*- coding: utf-8 -*-
"""Kelompok 12_Prediksi Penjualan-Walmart_FINISH

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pU4N9-m_oZcG6aAzYSwTdFvAIBB1HEnn

# **KELOMPOK 12 TUGAS BESAR DEEP LEARNING**


Nama Anggota Kelompok :

1. Sarah Natalia Geraldine - 121450022

2. Angelica Noviana - 121450064

3. Afifah Syaharani - 121450097

4. Muhammad Rendy -121450045

5. Ericson Chandra Sihombing - 121450026
"""

!pip install tensorflow

"""## Import Library"""

import numpy as np
import pandas as pd
import random
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from pandas.tseries.offsets import MonthBegin, MonthEnd
from keras.callbacks import EarlyStopping
import tensorflow as tf
from tensorflow.keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout, Input
from keras.callbacks import ReduceLROnPlateau
from keras import regularizers

"""## Load Data"""

# Load dataset
walmart_data = pd.read_csv('/content/Walmart.csv')
# df.dtypes
# df.shape
walmart_data['Date'] = pd.to_datetime(walmart_data['Date'], format='%d-%m-%Y')
walmart_data.head()
# data.set_index('Date', inplace=True)

# # Pilih kolom target
# data = data[['Weekly_Sales']]

# Transform the data to aggregate weekly sales
transformed_data = (
    walmart_data.groupby('Date').agg(
        sum_weekly_sales=('Weekly_Sales', 'sum')
    ).reset_index()
)

# Normalize the sum_weekly_sales data
scaler = MinMaxScaler(feature_range=(0, 1))
transformed_data['scaled_sales'] = scaler.fit_transform(transformed_data[['sum_weekly_sales']])

# Create the visualization
plt.figure(figsize=(12, 6))
plt.plot(transformed_data['Date'], transformed_data['sum_weekly_sales'], marker='o', color='b', label='Weekly Sales')

# Formatting the plot
plt.title('Sum of Weekly Sales Over Time', fontsize=16)
plt.xlabel('Date', fontsize=12)
plt.ylabel('Sum of Weekly Sales', fontsize=12)
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()

# Show the plot
plt.show()

"""## Spliting Data"""

# Set the random seed for reproducibility
np.random.seed(112)

# Menentukan ukuran jendela
window_size = 12

# Fungsi untuk membuat jendela
def create_windows(data, window_size):
    X, y = [], []
    for i in range(len(data) - window_size):
        X.append(data[i:i + window_size])
        y.append(data[i + window_size])  # Target adalah nilai setelah jendela
    return np.array(X), np.array(y)

# Menggunakan fungsi untuk membuat jendela
X, y = create_windows(transformed_data['scaled_sales'], window_size)

# Menampilkan hasil
# print("Input (X):")
# print(X)
# print("Target (y):")
# print(y)

# Mengubah bentuk data untuk LSTM
X = np.reshape(X, (X.shape[0], X.shape[1], 1))

# Split data menjadi training dan testing
split = int(len(X) * 0.8)
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

print("Shape of X:", X.shape)

# Memastikan bentuk y
print("Shape of y:", y.shape)

"""## Modeling"""

# Define the model
model = Sequential()
model.add(Input(shape=(window_size, 1)))  # Input layer

# Adding multiple LSTM layers
model.add(LSTM(256, return_sequences=True))  # First LSTM layer with more units
model.add(Dropout(0.3))  # Dropout layer

model.add(LSTM(128, return_sequences=True))  # Second LSTM layer with more units
model.add(Dropout(0.3))  # Dropout layer

model.add(LSTM(64, return_sequences=True))  # Third LSTM layer
model.add(Dropout(0.3))  # Dropout layer

model.add(LSTM(32, return_sequences=False))  # Fourth LSTM layer
model.add(Dropout(0.3))  # Dropout layer

# Adding Dense layers
model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))  # First Dense layer with L2 Regularization
model.add(Dropout(0.3))  # Dropout layer

model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)))  # Second Dense layer with L2 Regularization
model.add(Dense(1))  # Output layer

# Mengkompilasi model
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])

# Menampilkan ringkasan model
model.summary()

# Early stopping and learning rate reduction
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)

"""### Training"""

# Train model
history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=50,
    batch_size=64,
    verbose=1
)

"""### Evaluate"""

# Visualisasi loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()

# Prediksi
y_pred = model.predict(X_test)

# Inverse transform prediksi dan nilai asli
y_pred_rescaled = scaler.inverse_transform(y_pred)
y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))

# Evaluasi model
def mean_absolute_percentage_error(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

rmse = np.sqrt(mean_squared_error(y_test_rescaled, y_pred_rescaled))
mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)
mape = mean_absolute_percentage_error(y_test_rescaled, y_pred_rescaled)

print(f"RMSE: {rmse}")
print(f"MAE: {mae}")
print(f"MAPE: {mape:.2f}%")

"""## Predict"""

def predict_future(model, last_window, n_steps):
    predictions = []
    current_input = last_window

    for step in range(n_steps):
        # Reshape input untuk model LSTM
        current_input = current_input.reshape((1, window_size, 1))

        # Melakukan prediksi
        next_pred = model.predict(current_input)

        # Menyimpan prediksi
        predictions.append(next_pred[0, 0])

        # Memperbarui input untuk prediksi berikutnya
        # Menggunakan np.concatenate untuk menggabungkan array dengan dimensi yang benar
        current_input = np.concatenate((current_input[:, 1:, :], next_pred.reshape(1, 1, 1)), axis=1)

        # Menampilkan last_window setiap memprediksi minggu berikutnya
        print(f"Prediksi untuk minggu ke-{step + 1}: {next_pred[0, 0]}")
        print(f"Last window setelah prediksi: {current_input.flatten()}")  # Menampilkan jendela terakhir

    return np.array(predictions)

# Mengambil jendela terakhir dari data
last_window = X[-1]  # Mengambil jendela terakhir dari X

# Prediksi 4 minggu ke depan
n_weeks_to_predict = 8
future_predictions = predict_future(model, last_window, n_weeks_to_predict)
future_predictions

# EVALUASI MODEL UNTUK HASIL PREDIKSI

from sklearn.metrics import mean_squared_error
import numpy as np

# Fungsi untuk menghitung MAPE
def mean_absolute_percentage_error(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

# Misalkan kita menggunakan data test sebagai nilai aktual
y_true = y_test  # Data aktual dari test set
y_pred = model.predict(X_test)

# Invers transformasi data untuk mendapatkan nilai asli
y_true_rescaled = scaler.inverse_transform(y_true.reshape(-1, 1))
y_pred_rescaled = scaler.inverse_transform(y_pred.reshape(-1, 1))

# 1. Menghitung RMSE (Root Mean Squared Error)
rmse = np.sqrt(mean_squared_error(y_true_rescaled, y_pred_rescaled))
print(f'RMSE: {rmse:.2f}')

# 2. Menghitung MAE (Mean Absolute Error)
mae = mean_absolute_error(y_true_rescaled, y_pred_rescaled)
print(f'MAE: {mae:.2f}')

# 3. Menghitung MAPE (Mean Absolute Percentage Error)
mape = np.mean(np.abs((y_true_rescaled - y_pred_rescaled) / y_true_rescaled)) * 100
print(f'MAPE: {mape:.2f}%')

# future_predictions = scaler.inverse_transform(future_predictions.reshape(-1, 1))

# Visualisasi hasil prediksi
plt.figure(figsize=(18, 8))
# Plot data historis
plt.plot(range(len(transformed_data['scaled_sales'])), transformed_data['scaled_sales'].values, label='Data Historis', color='blue')

# Plot prediksi masa depan
# Pastikan rentang indeks untuk prediksi masa depan dimulai dari akhir data historis
plt.plot(range(len(transformed_data['scaled_sales']), len(transformed_data['scaled_sales']) + n_weeks_to_predict), future_predictions, label='Prediksi Masa Depan', color='orange')

plt.title('Prediksi Penjualan untuk 8 Minggu ke Depan')
plt.ylabel('Penjualan yang Dinormalisasi')
plt.xlabel('Langkah Waktu')
plt.legend()
plt.show()